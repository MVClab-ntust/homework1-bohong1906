{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxKMWo-elK71"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oApJKcANlQ5U"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import argparse\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzishWZ1l4Mn"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "    project=\"CIFAR-100-deep-learning\",\n",
        "    config={\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"architecture\": \"ResNet18\",\n",
        "    \"dataset\": \"CIFAR-100\",\n",
        "    \"epochs\": 1,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RAjbnvK5l72g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# transform before training\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIehVvT8SXus"
      },
      "outputs": [],
      "source": [
        "# load train, valid, test data\n",
        "trainset, validset = torch.utils.data.random_split(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform = transform),\n",
        "    lengths=[45000, 5000])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,shuffle=True, num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=16, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "      'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
        "      'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "      'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "      'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "      'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
        "      'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "      'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "      'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "      'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "      'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "      'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "      'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "      'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "      'baby', 'boy', 'girl', 'man', 'woman',\n",
        "      'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "      'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "      'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "      'bicycle', 'bus', 'motorcycle', 'pickup' 'truck', 'train',\n",
        "      'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bKAolR8Qa-02"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding = 1)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding = 1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.downsample = downsample\n",
        "  def forward(self, x):\n",
        "    residual=x\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    if(self.downsample):  #add shortcut\n",
        "        residual = self.downsample(x)\n",
        "    out += residual\n",
        "    out = self.relu(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "EE6q8aobYAIW"
      },
      "outputs": [],
      "source": [
        "# creat network\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, ResBlock):\n",
        "    super(Net, self).__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv = nn.Conv2d(3, 64, 3)\n",
        "    self.bn = torch.nn.BatchNorm2d(64)\n",
        "    self.relu = torch.nn.ReLU(inplace=True)\n",
        "    self.layer1 = self._make_layers(ResBlock, 64, 2)\n",
        "    self.layer2 = self._make_layers(ResBlock, 128, 2, 2)\n",
        "    self.layer3 = self._make_layers(ResBlock, 256, 2, 2)\n",
        "    self.layer4 = self._make_layers(ResBlock, 512, 2, 2)\n",
        "    self.avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = torch.nn.Linear(512, 100)\n",
        "\n",
        "  def _make_layers(self, ResBlock, out_channels, blocks, stride=1):\n",
        "    downsample = None\n",
        "    # shortcut tensor size is needed to same as ResBlock result, here is processing shortcut tensor size\n",
        "    if (stride != 1) or (self.in_channels != out_channels):\n",
        "        downsample = torch.nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, out_channels,1, stride=stride),\n",
        "            torch.nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "    layers = []\n",
        "    layers.append(ResBlock(self.in_channels, out_channels, stride, downsample))\n",
        "    self.in_channels = out_channels\n",
        "    for i in range(1, blocks):\n",
        "        layers.append(ResBlock(out_channels, out_channels))\n",
        "    return torch.nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "net = Net(ResBlock).to(device)\n",
        "\n",
        "# optimizer and loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaTUxcablb10"
      },
      "outputs": [],
      "source": [
        "# start training\n",
        "from tqdm.notebook import tqdm\n",
        "progress_bar = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc='Training' )\n",
        "\n",
        "for epoch in range(1):  # epoch\n",
        "  running_loss = 0.0\n",
        "  for i, data in (enumerate(trainloader, 0)):\n",
        "\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    # zero gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward, backward, optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    wandb.log({\"loss\": loss})\n",
        "    progress_bar.update(1)\n",
        "    running_loss += loss.item()\n",
        "    if i % 250 == 0:\n",
        "      # validation\n",
        "      net.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "        for data in validloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "      progress_bar.set_postfix(accuracy=100 * correct / total)\n",
        "      wandb.log({\"accuracy\": correct/total})\n",
        "    running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvIzbP6vrsmE"
      },
      "outputs": [],
      "source": [
        "# test network on test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "# calculate accuracy\n",
        "class_correct = list(0. for i in range(100))\n",
        "class_total = list(0. for i in range(100))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(100):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVtDwTZE9dXI"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}